import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import confusion_matrix, accuracy_score
from sklearn.preprocessing import LabelEncoder

# ================= è¨­å®šå€ =================
FEATURE_FILE = "album_features_dinov2.pt" # ä½ çš„ç‰¹å¾µæª”è·¯å¾‘
BATCH_SIZE = 64
LEARNING_RATE = 0.001
EPOCHS = 30  # æ¯ä¸€æŠ˜è¦è¨“ç·´å¹¾è¼ª (å› ç‚ºåªæœ‰ MLPï¼Œå¾ˆå¿«)
HIDDEN_DIM = 512 # éš±è—å±¤ç¥ç¶“å…ƒæ•¸é‡
DROPOUT_RATE = 0.5 # é˜²æ­¢éæ“¬åˆ (é‡è¦ï¼)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

# ================= 1. è³‡æ–™æº–å‚™ (Data Prep) =================
print("æ­£åœ¨è¼‰å…¥ç‰¹å¾µè³‡æ–™...")
raw_data = torch.load(FEATURE_FILE, map_location='cpu')

# è½‰æ›è³‡æ–™æ ¼å¼
X_list = []
y_list = []

for item in raw_data:
    # å–å¾—ç‰¹å¾µ (ç¢ºä¿æ˜¯ 1D å‘é‡)
    embedding = item['embedding'].float()
    X_list.append(embedding)
    
    # å–å¾—å¹´ä»½ä¸¦è½‰ç‚ºå¹´ä»£ (Decade)
    # ä¾‹å¦‚ 1963 -> 1960, 2023 -> 2020
    year = item['year']
    decade = (year // 10) * 10 
    y_list.append(decade)

# è½‰æˆ PyTorch Tensor
X = torch.stack(X_list) # Shape: (N, 768) or (N, 1024)
y_raw = np.array(y_list)

# ä½¿ç”¨ LabelEncoder æŠŠå¹´ä»£ (1960, 1970...) è½‰æˆç´¢å¼• (0, 1, 2...)
label_encoder = LabelEncoder()
y = label_encoder.fit_transform(y_raw) # é€™æ˜¯æˆ‘å€‘è¨“ç·´ç”¨çš„ Target
y = torch.tensor(y, dtype=torch.long)

# é¡¯ç¤ºé¡åˆ¥å°æ‡‰é—œä¿‚
class_names = label_encoder.classes_
print(f"ç¸½è³‡æ–™ç­†æ•¸: {len(X)}")
print(f"ç‰¹å¾µç¶­åº¦: {X.shape[1]}")
print(f"é¡åˆ¥å°æ‡‰: {dict(zip(range(len(class_names)), class_names))}")

# ================= 2. å®šç¾© MLP æ¨¡å‹ =================
class DecadeClassifier(nn.Module):
    def __init__(self, input_dim, hidden_dim, num_classes):
        super(DecadeClassifier, self).__init__()
        # æ¶æ§‹: Input -> Linear -> ReLU -> Dropout -> Linear -> Output
        self.layer1 = nn.Linear(input_dim, hidden_dim)
        self.relu = nn.ReLU()
        self.dropout = nn.Dropout(DROPOUT_RATE) 
        self.layer2 = nn.Linear(hidden_dim, num_classes)
        
    def forward(self, x):
        x = self.layer1(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.layer2(x)
        return x

# ================= 3. 5-Fold Cross-Validation è¨“ç·´è¿´åœˆ =================
kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

# å„²å­˜æ¯ä¸€æŠ˜çš„çµæœä»¥ä¾¿æœ€å¾Œå¹³å‡
fold_accuracies = []
all_preds = []
all_labels = []

print("\nğŸš€ é–‹å§‹ 5-Fold Cross Validation...")

# è½‰å› numpy åš split ç´¢å¼• (sklearn éœ€è¦ numpy)
X_numpy = X.numpy()
y_numpy = y.numpy()

for fold, (train_idx, val_idx) in enumerate(kfold.split(X_numpy, y_numpy)):
    print(f"\n--- Fold {fold + 1} / 5 ---")
    
    # åˆ‡åˆ†è³‡æ–™
    X_train, X_val = X[train_idx].to(device), X[val_idx].to(device)
    y_train, y_val = y[train_idx].to(device), y[val_idx].to(device)
    
    # åˆå§‹åŒ–æ¨¡å‹
    input_dim = X.shape[1]
    num_classes = len(class_names)
    model = DecadeClassifier(input_dim, HIDDEN_DIM, num_classes).to(device)
    
    # å®šç¾© Loss å’Œ Optimizer
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)
    
    # è¨“ç·´è¿´åœˆ (Training Loop)
    model.train()
    for epoch in range(EPOCHS):
        optimizer.zero_grad()
        outputs = model(X_train)
        loss = criterion(outputs, y_train)
        loss.backward()
        optimizer.step()
        
        # (å¯é¸) æ¯ 10 epoch å°ä¸€æ¬¡ loss
        # if (epoch+1) % 10 == 0:
        #     print(f"Epoch {epoch+1}, Loss: {loss.item():.4f}")
            
    # é©—è­‰è¿´åœˆ (Validation Loop)
    model.eval()
    with torch.no_grad():
        val_outputs = model(X_val)
        _, val_preds = torch.max(val_outputs, 1)
        
        # è¨ˆç®—æº–ç¢ºç‡
        acc = accuracy_score(y_val.cpu(), val_preds.cpu())
        fold_accuracies.append(acc)
        print(f"Fold {fold+1} Accuracy: {acc:.4f}")
        
        # æ”¶é›†çµæœç•« Confusion Matrix
        all_preds.extend(val_preds.cpu().numpy())
        all_labels.extend(y_val.cpu().numpy())

# ================= 4. çµæœåˆ†æ =================
print("\n" + "="*30)
print(f"å¹³å‡æº–ç¢ºç‡ (Mean Accuracy): {np.mean(fold_accuracies):.4f}")
print("="*30)

# ç¹ªè£½ Confusion Matrix
cm = confusion_matrix(all_labels, all_preds)
plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
            xticklabels=class_names, yticklabels=class_names)
plt.xlabel('Predicted Decade')
plt.ylabel('True Decade')
plt.title('Confusion Matrix (All Folds)')
plt.show()