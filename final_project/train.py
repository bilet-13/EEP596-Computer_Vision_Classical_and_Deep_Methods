import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import confusion_matrix, accuracy_score
from sklearn.preprocessing import LabelEncoder

FEATURE_FILE = "album_features_dinov2.pt" 
BATCH_SIZE = 64
LEARNING_RATE = 0.001
EPOCHS = 30  
HIDDEN_DIM = 512
DROPOUT_RATE = 0.5 

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

print("æ­£åœ¨è¼‰å…¥ç‰¹å¾µè³‡æ–™...")
raw_data = torch.load(FEATURE_FILE, map_location='cpu')

X_list = []
y_list = []
filenames = []

for item in raw_data:
    embedding = item['embedding'].float()
    X_list.append(embedding)
    
    # å–å¾—å¹´ä»½ä¸¦è½‰ç‚ºå¹´ä»£ (Decade)
    # ä¾‹å¦‚ 1963 -> 1960, 2023 -> 2020
    year = item['year']
    decade = (year // 10) * 10 
    y_list.append(decade)

    # ç´€éŒ„æª”åï¼Œè‹¥ä¸å­˜åœ¨å‰‡ä»¥ç´¢å¼•ä»£æ›¿
    filenames.append(item.get('filename', f"idx_{len(filenames)}"))

# è½‰æˆ PyTorch Tensor
X = torch.stack(X_list) # Shape: (N, 768) or (N, 1024)
y_raw = np.array(y_list)
filenames = np.array(filenames)

# ä½¿ç”¨ LabelEncoder æŠŠå¹´ä»£ (1960, 1970...) è½‰æˆç´¢å¼• (0, 1, 2...)
label_encoder = LabelEncoder()
y = label_encoder.fit_transform(y_raw) # é€™æ˜¯æˆ‘å€‘è¨“ç·´ç”¨çš„ Target
y = torch.tensor(y, dtype=torch.long)

# é¡¯ç¤ºé¡åˆ¥å°æ‡‰é—œä¿‚
class_names = label_encoder.classes_
print(f"ç¸½è³‡æ–™ç­†æ•¸: {len(X)}")
print(f"ç‰¹å¾µç¶­åº¦: {X.shape[1]}")
print(f"é¡åˆ¥å°æ‡‰: {dict(zip(range(len(class_names)), class_names))}")

# ================= 2. å®šç¾© MLP æ¨¡å‹ =================
class DecadeClassifier(nn.Module):
    def __init__(self, input_dim, hidden_dim, num_classes):
        super(DecadeClassifier, self).__init__()
        # æ¶æ§‹: Input -> Linear -> ReLU -> Dropout -> Linear -> Output
        self.layer1 = nn.Linear(input_dim, hidden_dim)
        self.relu = nn.ReLU()
        self.dropout = nn.Dropout(DROPOUT_RATE) 
        self.layer2 = nn.Linear(hidden_dim, num_classes)
        
    def forward(self, x):
        x = self.layer1(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.layer2(x)
        return x

# ================= 3. 5-Fold Cross-Validation è¨“ç·´è¿´åœˆ =================
kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

# å„²å­˜æ¯ä¸€æŠ˜çš„çµæœä»¥ä¾¿æœ€å¾Œå¹³å‡
fold_accuracies = []
all_preds = []
all_labels = []

# æ”¶é›†æ¯å€‹å¹´ä»£çš„é«˜ä¿¡å¿ƒæ¡ˆä¾‹
best_correct_by_class = {i: [] for i in range(len(class_names))}
best_wrong_by_class = {i: [] for i in range(len(class_names))}

print("\nğŸš€ é–‹å§‹ 5-Fold Cross Validation...")

# è½‰å› numpy åš split ç´¢å¼• (sklearn éœ€è¦ numpy)
X_numpy = X.numpy()
y_numpy = y.numpy()

for fold, (train_idx, val_idx) in enumerate(kfold.split(X_numpy, y_numpy)):
    print(f"\n--- Fold {fold + 1} / 5 ---")
    
    # åˆ‡åˆ†è³‡æ–™
    X_train, X_val = X[train_idx].to(device), X[val_idx].to(device)
    y_train, y_val = y[train_idx].to(device), y[val_idx].to(device)
    
    # åˆå§‹åŒ–æ¨¡å‹
    input_dim = X.shape[1]
    num_classes = len(class_names)
    model = DecadeClassifier(input_dim, HIDDEN_DIM, num_classes).to(device)
    
    # å®šç¾© Loss å’Œ Optimizer
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)
    
    # è¨“ç·´è¿´åœˆ (Training Loop)
    model.train()
    for epoch in range(EPOCHS):
        optimizer.zero_grad()
        outputs = model(X_train)
        loss = criterion(outputs, y_train)
        loss.backward()
        optimizer.step()
        
        # (å¯é¸) æ¯ 10 epoch å°ä¸€æ¬¡ loss
        if (epoch+1) % 10 == 0:
            print(f"Epoch {epoch+1}, Loss: {loss.item():.4f}")
            
    # é©—è­‰è¿´åœˆ (Validation Loop)
    model.eval()
    with torch.no_grad():
        val_outputs = model(X_val)
        val_probs = torch.softmax(val_outputs, dim=1)

        # Top-1 Accuracy (å®Œå…¨æ­£ç¢º)
        val_max_probs, val_preds_top1 = torch.max(val_probs, 1)
        acc_top1 = accuracy_score(y_val.cpu(), val_preds_top1.cpu())
        
        # Off-by-One Accuracy (é æ¸¬å’ŒçœŸå¯¦ç›¸å·® â‰¤ 1 å€‹é¡åˆ¥)
        # ä¾‹å¦‚: çœŸå¯¦æ˜¯ 1970 (class 1), é æ¸¬ 1960 (class 0) æˆ– 1980 (class 2) ä¹Ÿç®—å°
        off_by_one_correct = np.abs(val_preds_top1.cpu().numpy() - y_val.cpu().numpy()) <= 1
        acc_off_by_one = off_by_one_correct.mean()
        
        # Top-2 Accuracy (å‰2åé æ¸¬ä¸­åªè¦æœ‰1å€‹å°å°±ç®—å°)
        _, val_preds_top2 = torch.topk(val_probs, 2, dim=1)
        acc_top2 = (val_preds_top2 == y_val.unsqueeze(1)).any(dim=1).float().mean().item()
        
        fold_accuracies.append(acc_top1)
        print(f"Fold {fold+1} Top-1 Accuracy: {acc_top1:.4f}, Off-by-One Accuracy: {acc_off_by_one:.4f}, Top-2 Accuracy: {acc_top2:.4f}")
        
        # æ”¶é›†çµæœç•« Confusion Matrix (ç”¨ Top-1)
        all_preds.extend(val_preds_top1.cpu().numpy())
        all_labels.extend(y_val.cpu().numpy())

        # æ”¶é›†é«˜ä¿¡å¿ƒæ¡ˆä¾‹ (ä¾çœŸå¯¦å¹´ä»£åˆ†çµ„)
        val_true = y_val.cpu().numpy()
        val_pred = val_preds_top1.cpu().numpy()
        val_conf = val_max_probs.cpu().numpy()
        val_files = filenames[val_idx]

        for t, p, conf, fname in zip(val_true, val_pred, val_conf, val_files):
            record = (float(conf), fname, int(p), int(t))
            if p == t:
                best_correct_by_class[t].append(record)
            else:
                best_wrong_by_class[t].append(record)

# ================= 4. çµæœåˆ†æ =================
print("\n" + "="*30)
print(f"å¹³å‡æº–ç¢ºç‡ (Mean Accuracy): {np.mean(fold_accuracies):.4f}")
print("="*30)

# é¡¯ç¤ºæ¯å€‹å¹´ä»£ä¿¡å¿ƒæœ€é«˜çš„æ­£ç¢º / éŒ¯èª¤æ¡ˆä¾‹ (å„å–å‰ 10 å¼µ)
print("\nğŸ“‚ æ¯å€‹å¹´ä»£çš„é«˜ä¿¡å¿ƒæ¡ˆä¾‹ (Top-10)")
for cls_idx, decade in enumerate(class_names):
    correct_sorted = sorted(best_correct_by_class[cls_idx], key=lambda x: x[0], reverse=True)[:10]
    wrong_sorted = sorted(best_wrong_by_class[cls_idx], key=lambda x: x[0], reverse=True)[:10]

    print(f"\n=== Decade: {decade} ===")
    print("Top-10 æ­£ç¢ºä¸”ä¿¡å¿ƒæœ€é«˜:")
    if correct_sorted:
        for conf, fname, pred_idx, true_idx in correct_sorted:
            pred_decade = class_names[pred_idx]
            print(f"  conf={conf:.3f} | pred={pred_decade} | true={class_names[true_idx]} | file={fname}")
    else:
        print("  (ç„¡)")

    print("Top-10 é æ¸¬éŒ¯ä½†ä¿¡å¿ƒæœ€é«˜:")
    if wrong_sorted:
        for conf, fname, pred_idx, true_idx in wrong_sorted:
            pred_decade = class_names[pred_idx]
            print(f"  conf={conf:.3f} | pred={pred_decade} | true={class_names[true_idx]} | file={fname}")
    else:
        print("  (ç„¡)")

# ç¹ªè£½ Confusion Matrix
cm = confusion_matrix(all_labels, all_preds)
plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
            xticklabels=class_names, yticklabels=class_names)
plt.xlabel('Predicted Decade')
plt.ylabel('True Decade')
plt.title('Confusion Matrix (All Folds)')
plt.show()