import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import StratifiedKFold, KFold
from sklearn.metrics import mean_absolute_error, r2_score

# ================= è¨­å®šå€ =================
FEATURE_FILE = "album_features_dinov2.pt" 
BATCH_SIZE = 64
LEARNING_RATE = 0.001
EPOCHS = 30  
HIDDEN_DIM = 512
DROPOUT_RATE = 0.5 

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

print("æ­£åœ¨è¼‰å…¥ç‰¹å¾µè³‡æ–™...")
raw_data = torch.load(FEATURE_FILE, map_location='cpu')

X_list = []
y_list = []

# --- 1. è³‡æ–™è™•ç†ï¼šä¿ç•™é€£çºŒå¹´ä»½ ---
min_year = 1960 # ç”¨ä¾†åšåŸºæº–é» (Normalization)

for item in raw_data:
    embedding = item['embedding'].float()
    X_list.append(embedding)
    
    # ç›´æ¥å–å¹´ä»½æ•¸å€¼
    year = item['year']
    
    # æ­£è¦åŒ–ï¼šæŠŠ 1960 è®Šæˆ 0, 1970 è®Šæˆ 10... é€™æ¨£æ¨¡å‹æ¯”è¼ƒå¥½å­¸
    # é æ¸¬æ™‚åªè¦æŠŠè¼¸å‡º + 1960 å°±èƒ½é‚„åŸ
    y_list.append(float(year - min_year))

X = torch.stack(X_list) 
y = torch.tensor(y_list, dtype=torch.float32).view(-1, 1) # Regression éœ€è¦ Shape ç‚º (N, 1)

print(f"ç¸½è³‡æ–™ç­†æ•¸: {len(X)}")
print(f"ç‰¹å¾µç¶­åº¦: {X.shape[1]}")
print(f"å¹´ä»½ç¯„åœ: {min_year} + [0 ~ {y.max().item()}]")

# ================= 2. å®šç¾© MLP æ¨¡å‹ (Regression) =================
class YearRegressor(nn.Module):
    def __init__(self, input_dim, hidden_dim):
        super(YearRegressor, self).__init__()
        # æ¶æ§‹: Input -> Linear -> ReLU -> Dropout -> Linear -> Output (1ç¶­)
        self.layer1 = nn.Linear(input_dim, hidden_dim)
        self.relu = nn.ReLU()
        self.dropout = nn.Dropout(DROPOUT_RATE) 
        self.layer2 = nn.Linear(hidden_dim, 1) # è¼¸å‡ºåªæœ‰ 1 å€‹æ•¸å€¼ (é æ¸¬å¹´ä»½)
        
    def forward(self, x):
        x = self.layer1(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.layer2(x)
        return x

# ================= 3. 5-Fold Cross-Validation =================
# å›æ­¸å•é¡Œé€šå¸¸ç”¨ KFold (Stratified æ˜¯çµ¦åˆ†é¡ç”¨çš„ï¼Œä½†å¦‚æœæƒ³ä¾å¹´ä»£åˆ†å±¤ä¹Ÿå¯ä»¥ç”¨ StratifiedKFold æ­é… binningï¼Œé€™é‚Šå…ˆç”¨ç°¡å–®çš„ KFold)
kfold = KFold(n_splits=5, shuffle=True, random_state=42)

fold_maes = [] # è¨˜éŒ„æ¯ä¸€æŠ˜çš„å¹³å‡èª¤å·® (å¹´)
all_preds = []
all_targets = []

print("\nğŸš€ é–‹å§‹ 5-Fold Cross Validation (Regression)...")

X_numpy = X.numpy()
y_numpy = y.numpy()

for fold, (train_idx, val_idx) in enumerate(kfold.split(X_numpy)):
    print(f"\n--- Fold {fold + 1} / 5 ---")
    
    # åˆ‡åˆ†è³‡æ–™
    X_train, X_val = X[train_idx].to(device), X[val_idx].to(device)
    y_train, y_val = y[train_idx].to(device), y[val_idx].to(device)
    
    # åˆå§‹åŒ–æ¨¡å‹
    input_dim = X.shape[1]
    model = YearRegressor(input_dim, HIDDEN_DIM).to(device)
    
    # å®šç¾© Loss (MSE ç”¨æ–¼è¨“ç·´ï¼Œå› ç‚ºå®ƒå°å¤§èª¤å·®æ‡²ç½°é‡ï¼Œæ”¶æ–‚å¿«)
    criterion = nn.MSELoss() 
    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)
    
    # è¨“ç·´è¿´åœˆ
    model.train()
    for epoch in range(EPOCHS):
        optimizer.zero_grad()
        outputs = model(X_train)
        loss = criterion(outputs, y_train) # MSE Loss
        loss.backward()
        optimizer.step()
        
        if (epoch+1) % 10 == 0:
            print(f"Epoch {epoch+1}, MSE Loss: {loss.item():.4f}")
            
    # é©—è­‰è¿´åœˆ
    model.eval()
    with torch.no_grad():
        val_outputs = model(X_val)
        
        # é‚„åŸæˆå¹´ä»½ (åŠ ä¸Š min_year)
        preds_real_year = val_outputs.cpu().numpy() + min_year
        targets_real_year = y_val.cpu().numpy() + min_year
        
        # è¨ˆç®— MAE (å¹³å‡çµ•å°èª¤å·®) - é€™æ˜¯çµ¦äººé¡çœ‹çš„æŒ‡æ¨™
        # "å¹³å‡é æ¸¬éŒ¯å¹¾å¹´ï¼Ÿ"
        mae = mean_absolute_error(targets_real_year, preds_real_year)
        fold_maes.append(mae)
        
        print(f"Fold {fold+1} MAE: {mae:.4f} years (å¹³å‡èª¤å·® {mae:.1f} å¹´)")
        
        all_preds.extend(preds_real_year.flatten())
        all_targets.extend(targets_real_year.flatten())

# ================= 4. çµæœåˆ†æ =================
print("\n" + "="*30)
print(f"å¹³å‡ MAE (Mean Absolute Error): {np.mean(fold_maes):.4f} å¹´")
print("="*30)

# ç¹ªè£½ Scatter Plot (çœŸå¯¦å¹´ä»½ vs é æ¸¬å¹´ä»½)
plt.figure(figsize=(10, 8))
plt.scatter(all_targets, all_preds, alpha=0.3, s=10) # alphaè®“é‡ç–Šé»çœ‹å¾—å‡ºå¯†åº¦

# ç•«ä¸€æ¢å°è§’ç·š (å®Œç¾é æ¸¬ç·š)
min_val = min(min(all_targets), min(all_preds))
max_val = max(max(all_targets), max(all_preds))
plt.plot([min_val, max_val], [min_val, max_val], 'r--', label='Perfect Prediction')

plt.xlabel('True Year')
plt.ylabel('Predicted Year')
plt.title(f'Regression Result: True vs Predicted Year (MAE: {np.mean(fold_maes):.2f})')
plt.legend()
plt.grid(True, alpha=0.3)
plt.show()